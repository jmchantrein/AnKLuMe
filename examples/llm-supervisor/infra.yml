---
# infra.yml â€” Primary Source of Truth (PSOT)
#
# Describes your infrastructure at a high level. After editing, run:
#   make sync        # Generate/update Ansible files
#   make apply       # Apply to Incus
#
# See docs/SPEC.md section 5 for the full format reference.

# LLM supervisor: 2 isolated LLM domains + 1 supervisor domain.
# Each LLM runs in its own network. The supervisor communicates with
# both via API for monitoring and management.

project_name: llm-supervisor

global:
  base_subnet: "10.100"
  default_os_image: "images:debian/13"
  default_connection: community.general.incus
  default_user: root
  gpu_policy: shared

domains:
  anklume:
    description: "Administration and orchestration"
    subnet_id: 0
    ephemeral: false
    machines:
      llms-admin:
        description: "Ansible controller"
        type: lxc
        ip: "10.100.0.10"
        config:
          security.nesting: "true"
        roles:
          - base_system

  llm-alpha:
    description: "First LLM instance"
    subnet_id: 1
    ephemeral: false
    profiles:
      nvidia-compute:
        devices:
          gpu:
            type: gpu
            gputype: physical
    machines:
      llm-alpha-server:
        description: "Ollama server (primary model)"
        type: lxc
        ip: "10.100.1.10"
        gpu: true
        profiles:
          - default
          - nvidia-compute
        roles:
          - base_system
          - ollama_server

  llm-beta:
    description: "Second LLM instance"
    subnet_id: 2
    ephemeral: false
    profiles:
      nvidia-compute:
        devices:
          gpu:
            type: gpu
            gputype: physical
    machines:
      llm-beta-server:
        description: "Ollama server (secondary model)"
        type: lxc
        ip: "10.100.2.10"
        gpu: true
        profiles:
          - default
          - nvidia-compute
        roles:
          - base_system
          - ollama_server

  supervisor:
    description: "Supervisor monitoring both LLMs"
    subnet_id: 3
    ephemeral: false
    machines:
      llm-supervisor:
        description: "Supervisor container"
        type: lxc
        ip: "10.100.3.10"
        roles:
          - base_system
      llm-webui:
        description: "Open WebUI for interacting with LLMs"
        type: lxc
        ip: "10.100.3.11"
        roles:
          - base_system
          - open_webui
