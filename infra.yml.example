# infra.yml — Primary Source of Truth (PSOT)
#
# Describes your infrastructure at a high level. After editing, run:
#   make sync        # Generate/update Ansible files
#   make apply       # Apply to Incus
#
# See docs/SPEC.md section 5 for the full format reference.
#
# The generated Ansible files (inventory/, group_vars/, host_vars/) are
# the Secondary Source of Truth. You can freely edit them outside the
# === MANAGED === sections. Both this file and the generated files
# should be committed to git.

project_name: my-infra

global:
  base_subnet: "192.168"              # Domains use <base_subnet>.<subnet_id>.0/24
  default_os_image: "images:debian/13"
  default_connection: community.general.incus
  default_user: root

domains: {}
  # Uncomment and customize the example below to define your first domain:
  #
  # admin:
  #   description: "Administration and orchestration"
  #   subnet_id: 0                     # → 192.168.0.0/24 (unique, 0-254)
  #   machines:
  #     admin-ansible:
  #       description: "Ansible controller — drives the whole infra"
  #       type: lxc                    # "lxc" or "vm"
  #       ip: "192.168.0.10"           # Static IP (omit for DHCP)
  #       config:
  #         security.nesting: "true"
  #       roles:
  #         - base_system
  #
  # work:
  #   description: "Professional environment"
  #   subnet_id: 1
  #   machines:
  #     dev-workspace:
  #       description: "Main development workspace"
  #       type: lxc
  #       ip: "192.168.1.10"
  #       config:
  #         limits.cpu: "4"
  #         limits.memory: "8GiB"
  #       roles:
  #         - base_system
  #         - dev_tools
  #
  # gpu-lab:
  #   description: "GPU-enabled services (LLM, ML)"
  #   subnet_id: 2
  #   profiles:
  #     nvidia-compute:
  #       description: "NVIDIA GPU passthrough"
  #       devices:
  #         gpu:
  #           type: gpu
  #       config:
  #         nvidia.runtime: "true"
  #   machines:
  #     llm-server:
  #       description: "Local LLM inference server"
  #       type: lxc
  #       ip: "192.168.2.10"
  #       gpu: true
  #       profiles:
  #         - default
  #         - nvidia-compute
  #       config:
  #         limits.cpu: "8"
  #         limits.memory: "32GiB"
  #       storage_volumes:
  #         models:
  #           size: "200GiB"
  #           path: /data/models
  #       roles:
  #         - base_system
